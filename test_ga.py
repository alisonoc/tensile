import math
import os
import sys
import subprocess
import pandas as pd
import numpy as np
import random
import matplotlib.pyplot as plt
import matplotlib.style as style
from sklearn.metrics import mean_absolute_percentage_error
from B_SCR.general_functions import load_json_file, write_json_file
from B_SCR.plots import *
import itertools

marker = itertools.cycle(('s', 'v', 'o', 'd', '+', '*', 'x'))
style.use('tableau-colorblind10')
plt.rcParams["figure.figsize"] = (6, 6)
##set font size
font = {'family': 'sans-serif',
		'weight': 'normal',
		'size': 14}
plt.rc('font', **font)

"""
TEST TOP 5 ML PRODUCED GTN PARAMETERS GENERATED BY MANISH SHAH USING GA ALGORITHM

"""


def build_command_string(script=None, cae=None, job_dic_pth=None, job_dic=None):
	# ##DIFFERENTIATE BETWEEN CAE AND VIEWER
	if cae:
		caller = 'abaqus cae noGui='
	else:
		caller = 'abaqus viewer database=' + job_dic['job_id'] + ' noGui='
	# ##ADD THE BUILD/PP SCRIPT TO CALLER
	caller = caller + script
	# ##PROVIDE ADDRESS FOR JOB DICTIONARY
	if job_dic_pth:
		# ##CREATE COMMAND INITIALISER WITH CALLER
		c = ['cmd.exe', '/C', caller, '--']
		# ##APPEND STRING ARGS TO COMMAND LIST
		c.append(job_dic_pth)
	else:
		c = ['cmd.exe', '/C', caller]
	# ##RETURN COMMAND LIST
	return c


def call_cae(job_dic_pth=None, cwd=None, aba_dir=None, script=None, job_dic=None):
	"""
    Function to call Abaqus CAE
    :param job_file: filepath to job dictionary (json accessible)
    :param cwd: the current working directory
    :param aba_dir: the directory to which abaqus files should be saved
    :param script: the abaqus build script to be used to generate/execute model
    :param job_dic: dictionary of job data (python only)
    :return: job name and error codes
    """
	# SET CAE TO TRUE
	cae = True
	# CHANGE TO OUTPUT DIRECTORY
	os.chdir(aba_dir)
	# ##BUILD COMMAND STRING
	command = build_command_string(script=script, cae=cae, job_dic_pth=job_dic_pth)
	# ##RUN SUBPROCESS COMMAND
	p1 = subprocess.run(command,
						stdout=subprocess.PIPE,
						stderr=subprocess.PIPE,
						text=True)
	# ##RETURN TO ORIGINAL WORKING DIRECTORY (MAIN FILE)
	os.chdir(cwd)
	if p1.stdout == None or p1.stdout == '':
		# ##RETURN JOB NAME
		job_name = p1.stderr[p1.stderr.rfind('\n'):].strip('\n')
	else:
		abaqus_err = p1.stderr[:p1.stderr.find('\n')].strip('\n')
		p1.returncode = 1
		if 'server' in abaqus_err:
			print('Exit with error - please turn on Forticlient')
		# ##RETURN JOB NAME
		job_name = p1.stderr[p1.stderr.rfind('\n'):].strip('\n')
		print('JOB %s EXITED WITH ERROR' % (job_name))
		print(p1.stderr)
	return job_name, p1.returncode


def call_viewer(cwd=None, aba_dir=None, script=None, job_dic_pth=None, job_dic=None):
	# SET CAE TO FALSE
	cae = False
	# CHANGE TO OUTPUT DIRECTORY
	os.chdir(aba_dir)
	# ##BUILD COMMAND STRING
	command = build_command_string(script=script, cae=cae, job_dic=job_dic, job_dic_pth=job_dic_pth)
	# ##RUN SUBPROCESS COMMAND
	p1 = subprocess.run(command,
						stdout=subprocess.PIPE,
						stderr=subprocess.PIPE,
						text=True)
	# ##RETURN TO ORIGINAL WORKING DIRECTORY (MAIN FILE)
	os.chdir(cwd)
	# ##GET SYS WRITE OUT VALUES
	if p1.stdout == None or p1.stdout == '':
		output = p1.stderr.splitlines()
		# ##RETURN RESULTS FILENAME
		res_fname = output[-2]
		# ##RETURN NECK DIAMETER RESULTS
		neck_diameter = output[-1]
		return p1.returncode, res_fname, neck_diameter
	else:
		return p1.returncode


def create_directory(fname):
	if not os.path.exists(fname):
		os.makedirs(fname)


def round_down(num, digits):
	factor = 10 ** digits
	return np.floor(num * factor) / factor


def extract_abaqus_error_msg(job_name=None, result_dir=None):
	errors = []
	try:
		# ##READ ABAQUS MSG FILE AND EXTRACT ERROR MESSAGES
		with open(os.path.join(result_dir, '%s.msg' % job_name), 'rt') as f:
			for line in f.readlines():
				if '***ERROR:' in line:
					errors.append(line)
		# ##WRITE ONLY ERRORS TO FILE
		with open(os.path.join(result_dir, '%s_abaqus_errors.txt') % job_name, 'w') as f:
			for item in errors:
				f.write(item)
	except:
		pass


def del_rubbish(job_name=None, result_dir=None):
	# ##EXTRACT ABAQUS ERRORS
	extract_abaqus_error_msg(job_name=job_name, result_dir=result_dir)
	# ##SEARCH FOR JOB FILES BASED ON JOB NAME
	jobfilelist = [f for f in os.listdir(result_dir) if job_name in f]
	del_files = ['.com', '.log', '.prt', '.sta', '.dat', '.msg', '.txt', '.rpy*']
	keep_files = ['%s_abaqus_errors.txt' % job_name, '%s_pp_results.txt' % job_name]
	for f in jobfilelist:
		fname, ext = os.path.splitext(f)
		if (ext in del_files) and not (f in keep_files):
			os.remove(os.path.join(result_dir, f))


def compare_exp_sim(expx=None, expy=None, simx=None, simy=None, savepth=None):
	""" PLOT THE FORCE VERSUS DISPLACEMENT
    COMPARE EXPERIMENTAL DATA TO SIMULATED DATA.
    WE NEED TO SHOW PERFECT MATCH UP TO UTS"""
	fig, ax2d = plt.subplots()
	ax = np.ravel(ax2d)

	ax[0].plot(expx, expy / 1000, color='k', label='Experimental')
	ax[0].plot(simx, simy / 1000, label='Simulation')

	# AXES LIMITS
	ax[0].set_xlim([0, (1.1 * max(max(expx), max(simx)))])
	ax[0].set_ylim([0, (1.1 * max(max(expy) / 1000, max(simy) / 1000))])

	# AT LEAST FIVE TICK MARKS ON X AND Y AXES
	ax[0].xaxis.set_major_locator(plt.MaxNLocator(6))
	ax[0].yaxis.set_major_locator(plt.MaxNLocator(6))
	# AXES LABELS
	ax[0].set_xlabel('Displacement, mm')
	ax[0].set_ylabel('Force, kN')

	ax[0].legend(bbox_to_anchor=(1, 0),
				 loc='lower right',
				 borderaxespad=0,
				 frameon=False)
	# save figure
	plt.savefig(savepth,
				dpi=300,
				bbox_inches='tight')
	plt.close()


# ##CREATE DICTIONARY OF PATHS TO RELEVANT DIRECTORIES AND FILES
path_dic = {'raw_data': os.path.join(os.getcwd(), 'A_RAW_DATA'),
			'cwd': os.getcwd(),
			'build': os.path.join(os.getcwd(), 'B_SCR/aba_build_damage.py'),
			'postp': os.path.join(os.getcwd(), 'B_SCR/aba_pp.py'),
			'main_results': os.path.join(os.getcwd(), 'OUTPUT'),
			'material_results': os.path.join(os.path.join(os.getcwd(), 'OUTPUT'), 'P91_20_1')}

# ##CREATE DIRECTORY TO HOLD RESULTS FROM THIS ANALYSIS
rdir = os.path.join(path_dic['main_results'], 'test_ga')
create_directory(rdir)
path_dic['curr_results'] = rdir

# ##DICTIONARY HOLDING GEOMETRICAL DATA
geom_dic = {'GAUGE_LENGTH': 25.,
			'GAUGE_DIAMETER': 4.,
			'CONN_DIAMETER': 5.,
			'SPECIMEN_LENGTH': 72.,
			'ROUND_RADIUS': 3.,
			'THREADED_LENGTH': 15}

"""
READ GA ALGORITHM OUTPUT
"""
ga = pd.read_csv(os.path.join(path_dic['raw_data'], 'output_ga_1.csv'), header=0)
# ##SELECT TOP FIVE (BASED ON MAPE), DESELECT GA PREDICTED MAPE + Q3 param due to floating point precision error in abaqus
ga_lim = ga.iloc[0:5, 0:-1]
# ###recalc q3 from q1
ga_lim['Q3'] = round_down(ga_lim['Q3'], 4)

"""
CREATE ABAQUS MATERIAL PROPERTIES FILE
AND JOB TEXT FILE (CONTAINS ALL JOB PARAMETERS)
"""
# ##READ IN KNOWN DATA ABOUT THE MATERIAL
uts_dic = load_json_file(os.path.join(path_dic['material_results'], 'P91_20_1_properties.txt'))
# ##REMOVE SLOPE KEYWORD FROM UTS_DIC AS IRRELEVANT
del uts_dic['SLOPE']

"""
READ IN KNOWN EXPERIMENTAL TEST RESULTS FOR MAPE CALCS
"""
# ##READ IN EXPERIMENTAL LOAD/DISPLACEMENT
exp = pd.read_csv(os.path.join(path_dic['raw_data'], 'P91_20_1.csv'), header=1, names=['U', 'RF'])
# ##CONVERT FROM KN TO NEWTONS
exp['RF'] = exp['RF'] * 1000
# ####INTERPOLATE THE CURVE TO INCREASE NUM DATA POINTS
exp_eps_extrap = np.linspace(exp['U'].iloc[0], uts_dic['MAX_DISPLACEMENT'], num=500)
exp_sig_extrap = np.interp(exp_eps_extrap, exp['U'], exp['RF'])

# ##READ IN FORCE-DISPLACEMENT TO TRUE STRESS-STRAIN
tss = pd.read_csv(uts_dic['TRUE_TO_UTS'])
# ##dictionary to hold individual job parameters
job_dic = {}
# ##dictionary to hold all job status'
job_stats = {}
# ##PREVENT REINITIALISING JOBS MULTIPLE TIMES
dir_files = os.listdir(path_dic['curr_results'])
# ##FOR EACH SLOPE (M) VALUE CREATE ABAQUS TRUE STRESS-STRAIN EXTRAPOLATION
for job_num, row in ga_lim.iterrows():
	"""
	CREATE MATERIAL PROPERTIES
	"""
	if not ('ABA_JOB%s.csv' % job_num) in dir_files:
		# ##ADD SPECIMEN GEOMETRY INFO TO ROW
		geom = pd.Series(geom_dic)
		row = pd.concat([row, geom], axis=0)
		# ##ADD ELASTIC MATERIAL INFOR TO ROWS
		elastic = pd.Series(uts_dic)
		row = pd.concat([row, elastic], axis=0)
		# ##THE INTERCEPT IS A FUNCTION OF SIGMA TRUE UTS AND
		# # ##EPSILON TRUE UTS (C = SIG_T - M*ESP_T)
		c = uts_dic['TRUE_STRESS'] - (row['M'] * uts_dic['TRUE_STRAIN'])
		# ##EXTEND TO 2% PLASTIC STRAIN USING AT LEAST 15 DATA POINTS
		estrain = np.linspace(tss['TRUE_STRAIN'].iloc[-1], 0.2, num=15)
		# ##CALCULATE STRESS FROM STRAIN AND INTERCEPT VALUES
		estress = row['M'] * estrain + c
		# ##CONCAT STRAINS AND STRESSES INTO DATASET
		edf = pd.DataFrame(data={'TRUE_STRAIN': np.concatenate((tss['TRUE_STRAIN'], estrain.flatten()), axis=0),
								 'TRUE_STRESS': np.concatenate((tss['TRUE_STRESS'], estress.flatten()), axis=0)})
		# ##DROP ALL ROWS WHERE TRUE STRESS IS LESS THAN YIELD
		ind = edf.iloc[(edf['TRUE_STRESS'] - uts_dic['SIGMA_Y']).abs().argsort()[:1]].index[0]
		edf = edf[edf.index >= ind]
		# ##CALCULATE PLASTIC STRAIN
		edf['PLASTIC_STRAIN'] = edf['TRUE_STRAIN'] - (edf['TRUE_STRESS'] / uts_dic['E'])
		# ##ZERO PLASTIC STRAIN
		edf['PLASTIC_STRAIN'] = edf['PLASTIC_STRAIN'] - edf['PLASTIC_STRAIN'].iloc[0]
		if edf['PLASTIC_STRAIN'].any() < 0:
			edf['PLASTIC_STRAIN'] = np.where(edf['PLASTIC_STRAIN'] < 0, 1E-20, edf['PLASTIC_STRAIN'])
		# ##DROP TRUE STRAIN VALUES
		edf.drop('TRUE_STRAIN', axis=1, inplace=True)
		# ##DROP ANY STRAINS THAT DON'T ASCEND (abaqus restriction)
		aa = edf[edf['PLASTIC_STRAIN'].diff() < 0]
		if aa.empty:
			edf = edf.drop(labels=[1116])
		else:
			edf = edf.drop(aa.index)
		# ##SAVE RELEVANT INFO TO row series
		aa = pd.Series(
			['JOB%s' % str(job_num), path_dic['curr_results'], c,
			 os.path.join(path_dic['curr_results'], 'ABA_JOB%s.csv' % (str(job_num)))],
			index=['job_id', 'results_dir', 'material_intercept', 'plastic_properties'])
		job_dic = pd.concat([row, aa], axis=0).to_dict()
		# ##WRITE THE JOB DICTIONARY TO FILE
		job_dic_pth = write_json_file(dic=job_dic,
									  pth=path_dic['curr_results'],
									  filename='job_id%s.txt' % job_num)
		# ##SAVE ABAQUS DATA TO FILE
		edf.to_csv(aa['plastic_properties'], index=False)
	"""
	CHECK FOR ODB FILES IF NONE THEN RUN ABAQUS SIMULATION
	"""
	# ##CHECK ODB EXISTS
	if not ('JOB%s.odb' % job_num) in dir_files:
		# ##BUILD & EXECUTE ABAQUS MODEL
		job_name, rc_cae = call_cae(cwd=path_dic['cwd'],
									script=path_dic['build'],
									aba_dir=path_dic['curr_results'],
									job_dic_pth=job_dic_pth)
	"""
	IF SIMULATION IS TOTAL FAILURE (ODB_F) THEN REGISTER AS FAILED
	ELSE RUN POSTPROCESSOR
	"""
	# ##IF THE JOB FAILS WRITE RESULTS FILE
	if 'JOB%s.odb_f' % job_num in dir_files:
		final = {'sim_status': 'failed'}
		write_json_file(dic=final, pth=os.getcwd(), filename='%s_pp_results.txt' % job_name)
	else:
		if not ('JOB%s_pp_results.txt' % job_num) in dir_files:
			# ##PP ABAQUS
			job_dic_pth = os.path.join(path_dic['curr_results'], 'job_id%s.txt') % job_num
			job_dic = load_json_file(job_dic_pth)
			rc_viewer, res_fname, sim_status = call_viewer(cwd=path_dic['cwd'],
														   aba_dir=path_dic['curr_results'],
														   script=path_dic['postp'],
														   job_dic_pth=job_dic_pth,
														   job_dic=job_dic)

			"""
			CALCULATE MAPE FOR SIMULATION COMPARED TO EXPERIMENTAL
			"""
			# ##READ RESULTS
			fpth = os.path.join(path_dic['curr_results'], 'JOB%s_pp_results.txt' % job_num)
			bdic = load_json_file(fpth)
			####CALCULATE MAPE
			# ##INTERPOLATE SIMULATION VALUES TO XNEW, FILL UNKNOWN WITH ZERO
			simy = np.interp(exp_eps_extrap, bdic['U'], bdic['RF'], right=0.)
			mape = mean_absolute_percentage_error(exp_sig_extrap, simy) * 100
			# ##COMPARISON PLOT
			compare_exp_sim(expx=exp_eps_extrap, expy=exp_sig_extrap, simx=exp_eps_extrap, simy=simy,
							savepth=os.path.join(path_dic['curr_results'], 'JOB%s_expVsim.png' % (job_num)))
			job_stats[job_num] = {'sim_status': bdic['sim_status'], 'final_neck_diameter': bdic['final_neck_diameter'],
								 'ACTUAL_MAPE': mape}
	# ##DELETE RUBBISH FILES
	del_rubbish(job_name='JOB%s' % (job_num), result_dir=path_dic['curr_results'])

# ##CONVERT STATS TO DF
dfs = pd.DataFrame.from_dict(job_stats, orient='index')
ga = pd.concat([ga, dfs], axis=1)
# ##WRITE STATS RESULT
ga.to_csv(os.path.join(path_dic['curr_results'], 'output.csv'))